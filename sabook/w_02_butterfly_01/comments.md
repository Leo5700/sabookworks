

`"Эффект бабочки"`, ну до чего же дурацкий термин, просто удивительно, хотя и вполне естественно, что он получил широчайшее распространение в массах публики, не привыкшей заботиться о смысле слов, употребляемых не по делу и не кстати. 

A. Sprott и Чебурашка начинают издалека. 

Буде мы с вами занялись изучением хаоса и ставим своей целью поиск хаотического поведения решений некоторых уравнений, неплохо бы придумать какой-то простой (и дешёвый в вычислительном смысле) способ отличать хаос от не-хауса. Кстати сказать, отличить хаус от не-хауса нам поможет энциклопедия электронной музыки [music.ishkur.com](http://music.ishkur.com/) рекомендую к ознакомлению, но вернёмся к нашим шпротам. Нащупать способ нам поможет во-первых тот нехитрый факт, что хаотические процессы экстремально чувствительны к начальным условиям, а во-вторых свойство хаотических решений сходиться то к одним числам, то к другим.

Например, мы гоняем по итерациям логистическое уравнение при `R = 2`. Во первых, оно сходится к одному и тому же числу при любом `X` в диапазоне `0..1`, а во-вторых, сходятся они равномерно, то есть если взять начальное решение поближе к точке сходимости, то и сойдётся всё побыстрее. А если взять исходное значение и рядом с ним ещё одно, то на каждой итерации разница между ними будет всё уменьшаться и уменьшаться, причём, делать это она будет по экспоненте. Друзья мои, вы ещё помните, что такое экспонента?  

А вот извольте-ка посмотреть на этот хаос, хаос где всё у нас есть: берём `R = 4` и вдумчиво смотрим на расстояние между двумя исходными `X` от итерации к итерации. Решения начинают разбегаться, причём, разбегаться по экспоненте. Если с каждой итераций разница удваивается, говорят: "экспонента Ляпунова равна `1`", а если уменьшается в двое, говорят, что "экспонента Ляпунова равна `-1`". Здесь бы копнуть поглубже - почему именно степени двойки, а не десятки, не числа `e`? Ну да ладно. Великий математик Александр Михалыч Ляпунов родился в Ярославле в 1857 году, папаня его был известным астрономом, учителями его были Чебышев, Менделеев и Сеченов, так что не стоит удивляться, что Ляпунов изобрёл теорию устойчивости и много чего ещё. А "теория устойчивости" это полезная теория, без неё устойчивое управление самолётами, ракетами, ледоколами и атомными станциями было бы не особо-то и возможно.

В более общем случае, скажем, что экспонента Ляпунова определяет степень двойки, на которую расходятся (или сходятся) два близко взятых решения при итерациях уравнения. К примеру, если решения расходятся кратно `2` в степени `3` (то есть каждый раз в `8` раз), то экспонента Ляпунова равна тройке. А если решения каждую итерацию оказываются в `8` раз ближе друг к другу, но экспонента Ляпунова равна `-3` (т.е. расстояние умножается на `1/8`).

    difference = 2^L    (формула без номера, пусть будет)

Если экспонента Ляпунова `L` оказывается `> 1`, начинается хаос.

Допустим, хотим мы определить хаотичность поведения системы "в лоб" -- для этого надо сделать 100 итераций и посмотреть, сходятся решения в одно и то же число или же расходятся по разным углам, но есть способ более быстрый и более элегантный -- сравнить разницу решений до и после одной итерации и посмотреть, какому закону эта разница подчиняется. Для логистического уравнения закон должен выглядеть так:

    ΔX_n+1 / ΔX_n = R (1 - 2 X_n)    (формула 1D)

где `ΔX_n` разница между значениями на текущей итерации, а `ΔX_n+1` - на следующей.
Как нетрудно догадаться, в правой части уравнения 1D вылезла первая производная логистического уравнения, если перед этим раскрыть в нём скобки, а потом вынести за скобки `R`: 

    RX(1 - X) -> RX - RX^2 --> R - 2RX ---> R(1 - 2X)    (формула без номера 2)

производная это приращение, а приращение есть приращение, мы же итерируем, в конце концов, так что всё плюс-минус логично.

Вы наверное спросите: "Веничка, а когда же будет про эффект бабочки? Ты обещал рассказать про эффект бабочки!" - а я вам на это отвечу: "Будет, будет, но сначала обратите взор ваш вслед за мной мной из мира темного прошлого в век золотой, который «ей-ей, грядет», от третьего рейха, четвертого позвонка, пятой республики и семнадцатого съезда – вместе со мной, в мир вожделенного всеми иудеями пятого царства, седьмого неба и второго пришествия"...

Итак, мы получили уравнение 1D, правая часть которого каждую итерацию умножается на собственное предыдущее значение. Теперь, чтобы понять что в целом происходит с правой частью, удобно взять единицу (число 1.0) и умножить на него правую часть, потом то, что получилось умножить на новую правую часть, потом ещё и ещё. Ну а теперь, чтобы найти степень двойки, которая нам нужна (ведь как мы помним, `L` это как раз степень двойки, см. формулу без номера) возьмём на каждой итерации логарифм по основанию `2` от правой части, а затем, чтобы найти не суммарное а среднее значение экспоненты Ляпунова разделим всё это дело на число итераций N, за которое оно было получено. Проще некуда, ядрён батон. Запишем всё вышесказанное в виде уравнения:

    L = ∑log2|R(1 - 2 X_n)| / N    (формула 1E)

в этой формуле мы занимаемся складированием в сумму логарифма производной логистического уравнения, а потом делением всего этого на число членов суммы. А в итоге получаем значение экспоненты Ляпунова для каких-то заранее выбранных исходного `Х` и коэффициента `R`.

Запускаем код, видим привычную диаграмму Фейгенбаума и на ней зелёную кривую, похожую не то на горы не то на зубы. Это отрисовка экспонент Ляпунова для разных исходных условий. О как. Серая линия -- это ноль что для Фейгенбаума, что для Ляпунова.

Ну вот, мы и на Луне. И чего? экспоненту получили, посмотрели на неё внимательно, теперь нужно обобщить полученные знания на другие прочие уравнения, содержащие хаотические решения, хотя сейчас и совершенно непонятно, как это сделать.

А вот теперь немного хардкора: допустим, вы гоняете по итерациям какие-то уравнения (хмм.. может, "quadratic map" -- "квадратичные формы"), и видите, что у вас `L = 1`, что же это значит? Это значит, что если вы знали на какой-то итерации `Х` с точностью `0.01`, то на следующей ваша точность составит только `0.02`, затем `0.04` и так далее. После семи-восьми итераций ваша погрешность перешагнет за единицу, и если вы думали с помощью ваших уравнений что-то предсказывать (курсы ценных бумаг, погоду или что-нибудь ещё) -- имейте в виду, ваши предсказания окажутся бесполезными чуть более чем на 100%. Что интересно, если бы записать ваш `X` в виде двоичного числа, то на каждой итерации от него бы отваливалось одна самая правая цифра (ноль или единица), то есть на каждой итерации терялся бы один бит. Здесь автор явно подталкивает нас заглянуть в бездну теории информации имени Клода Шеннона, но мы этого делать не будем. Или будем? Есть неплохая научно-популярная книжка про теорию информации, `Дж. Пирс - Символы, Сигналы, Шумы - 1967, 337с` (гуглится в .djvu), можно за полчаса получить представление - что такое "бит", и что такое "энтропия", полезная книжка, короче говоря.
Я покрасил красным точки, в которых экспонента Ляпунова принимает значения, близкие к нулю, это точки бифуркации диаграммы Фейгенбаума, в этих точках решение находится на распутье, и заранее не ясно по какому рукаву реальности будут развиваться дальнейшие события, в таких точках даже небольшое (очень, очень на большое возмущение) может спровоцировать кардинальные, глобальные события -- "бабочка взмахивающая крыльями в Айове, может вызвать лавину эффектов, которые могут достигнуть высшей точки в дождливый сезон в Индонезии" (цитата из википедии). Впрочем, применительно к логистическому уравнению эффект бабочки наблюдается не в точках `L = 0`, а на границах красных зон из предыдущей части (той, где я рассказывал сплетни про великого математика Кантора и его множества), так что здесь я намеренно приврал, наглядности ради. Или не приврал?

Бабочки понимаш. Колумб, Ядрен-ть. Вообще, переход от "символьного мышления" математика к "вычислительному мышлению" программиста -- это всегда нетривиальная задачка, вот например так -- одно дело - понимать логику уравнения - и совсем другое - оживить уравнение в виде кода, проверить его практикой и получить хоть сколько-нибудь вменяемый результат, нам вот сейчас пришлось распилить уравнение на две части и одну часть запихнуть в цикл вычисления точек диаграммы Фейгенбаума, почему бы и нет. "Индейцы сидят возле юрты, на вигвамы задумчиво смотрят"..
